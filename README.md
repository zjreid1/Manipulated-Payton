# Manipulated-Payton
Notes for Manipulate-Inside the Cyberwar to Hijack Elections (Payton)

### Ch 1: How Did We Get Here

- Influence campaigns, misinformation, and manipulation go back to ancient times.

- Earlies example of an influence campaign dates back to ancient greece (Casey)
- Even the Iliad serves as ancient propaganda w/ other methods taking the form of poems, plays, and social gatherings to weild influence
- Ethos (authority), Pathos (emotion), Logos (logic) as different types of persuation and the corenrstone of effective propaganda
- Propaganda (as a term) started in 1622 with Pope Gregory XV establishing the "Sacred Congregation for the Propoggation of Faith" or Propaganda for short to train missionaries to convert as many as possible
- During WWI the UK made a concerted effort to get their information out first and cut Germany's undersa comms cables to cut off access to teh German press and established their own press agency (Wellington House)
- During WW2 the UK created the British Security Coordination was created w/ nearly 3000 agents to influence the US to join the allies as most of the US (80%) was isolationist at the time and also utilized the Ministrity of Information to disseminate propaganda via comics, newspapers, posters, etc...
- During the Cold War the Stasi and KGB would often use falsified documents and manipulation to control victims
- The USSR often used "active measures" for influence operations to include disinformation campaigns and even offering campaign money to US Presidential candidates (Humphrevy v Nixon 1968)
- One of the most famous disinfo campaigns was "Operation Denver" which attempted to convince people that the US started AIDS (Operation Infektion/Operation Denver)
(https://thereader.mitpress.mit.edu/operation-denver-kgb-aids-disinformation-campaign/) (https://en.wikipedia.org/wiki/Operation_Denver)
- Soviet backed 3rd party newspaper 1983 -> Russian magazine -> Government controlled news service -> Vaugely sounding medical report released by Russia -> Became global news being reported via CBS Evening news 1987
- As the late 1900s to early 2000s came with the advent of the internet, email, message boards, and social media were utilized more and more
- Operatives study/place disinfo in key user groups w/ sock accounts, reputation launder the disinfo via state sponsored news outlets, utilize 3rd party outlets to disseminate
- AI and LLMs make it easier to edit/forge information
- Between 1946 and 2000 the US had 81 influence operations and Russia had 36 (Levin) w/ the US influence campaigns were often directed at a specific country and often anti-communist in nature (Guatemala, Nicaragua, Italy, Iran, etc...)
- The US likely even intervened in the 1996 re-election of Boris Yelstin via IMF loan(s) to Russia and political consultants
- The US often uses politicial experts, financial backing, traditional media bombardment, and social media campaigns
- Common misinfo campaigns of the 1990s include Nigerian Prince Scamps, Mother Theresa Scams, even The Onion technically counts as legitimate news sources have run their headlines as fact blurring the lines between news and satire
- In 2013 a fake press release was promoted by legitimate news sources saying that a bank was withdrawing backing of a company causing $400 million in lost value before anyone caught on
- With Viral marketing/viral news can come good or bad and generally consist of 3 parts: A central emotionally charged message, attention capturing messenger, a receptive audience (i.e. ALS Ice bucket challenge, or the Tide Pod challenge)
- “Viral marketing seeks to spread information about a product or service from person to person by word of mouth or sharing via the Internet or e-mail. The goal of viral marketing is to inspire individuals to share a marketing message to friends, family, and other individuals to create exponential growth in the number of its recipients.”
- Misinfo can take the form of astroturfing attempting to mask powerful actors/politicians/corps and make them look like they have legitimate supporters.  The term originated in 1985 from Sen Lloyd Bensten "A fellow from Texas can tell the difference between grass and AstroTurf" describing letters that had been generated by insurance industry lobbysits
- Since political actors/governments have failed to stop disinfo/misinfo campaigns, they often leave it to social media companies to stop/combat them which is foolish at best
- The general end game is control, power, ideologies, money, etc...


### Ch 2: Motives and Targets: Manipuation in a post-truth, post-trust Era
- State actors promote misinfo to have populations doubt what to believe/who to trust so there is no "true" version of events and other narratives can take hold
- The Oxford Internet instutute finds that the majority of disinfo/misinfo campaigns are around political parties/election periods with at least 48 countries engaged in organized social media manipulation
- There is almost no legal, political, or military roucourse to social media/misinformation campaigns especially as legal and international institutions (such as NATO) struggle to keep up
- The largest/most well known action taken against a disinfo actor was against Cambridge Analytica which aggregated data on over 50 million FB users (FB claims it was a violation of user agreement, but CA says there was no data breach/violation)
- The CA data set was used to target specific demographics and voter blocs in multiple swing states for the 2016 election
- "...but it is hard to make the leap from data mining and data modeling to convincing someone how to vote for or against something. Or is it? In 2012, Facebook filed a patent titled “Determining User Personality Characteristics from Social Networking System Communications and Characteristics” the system that FB patented was/is to be used for advertising targeting and "positive interaction" with said advertising
- Manipulation campaigns often take place around Crypto/financal schemes and include pupmp and dump schemes, flash crashes, and spoofing (in the sense of fake boosting a crypto)
- Manipulation campaigns can be used to influence international events such as the JCPOA, protests, positive coverage about a regieme, etc... there are even (often internal) campaigns to convince citizens of a given country to keep spending money and contribute to the economy.
- Nation States will even go as far as posting negative comments on a pop star's social media to try and influence them (e.g. when Gaga met w/ the Dali Lama in 2016)


### Ch 3: How do you know what you think you know?
- Online influence campaigns will usually start with noraml information/events and then ramp up to misinformation and can result in real world consequences/actions (Heart of Texas FB page)
"""
We now know that Russians targeted politically activated citizens on social media, contacted them, and convinced them to participate in manufactured political events. In one mock rally that took place in front of the Cheesecake Factory in Palm Beach, Russians paid local Floridians to be actors in a skit, sent them scripts, and reimbursed them for materials. But when these Americans found out months later from the FBI that they’d been roped into a Russian operation, one of the participants, Anne Marie Thomas—the woman who had impersonated Hillary Clinton—shrugged it off. “I wasn’t used as a puppet,” she told one Radiolab reporter, noting that she had loved the idea so much that she did it on her own again without Russian encouragement, involvement, or payment. “I don’t feel like the Russians used me,” she later reiterated to the Palm Beach Post
"""

- Influence campaigns will often use wedge issues/devisive issues to drive engagement (race relations, politics, vaccines, etc...) and will often have specific/tailored messages for specific groups

### Ch 4: Manipulators and Their Methods

- Propaganda Campaigns are usually pursued through Dismissing claims, Distorting events, Distracting from stories, and Dismaying opponents
- A number of threat actors will engage in manipulation campaigns from Iran, to NK, to China, and Russia all with various aims including Brexit, PR, Sony Pictures, IP/Tibet, etc...
- Social Media companies and many corporations have neither the budget nor staffing to be able to catch manipulation campaigns early
- Even less well known actors are starting campaigns such as Lebanon, Hungary usually with the cycle of: fear, crackdown, justifying propaganda, fear
- The various methods used include control via blocking websites or platforms, preventying use of encryption, or restricting app types.  sometimes this is done during crisis, sometimes for various political reasons (e.g. Turkey blocking Wikipedia for having articles they didn't like)
- Oftentimes there are BS reasons i.e. China prevented livestreaming on certain apps because underage teenage mothers were streaming, which promoted/encouraged teen pregnancy, or Indonesia establishing the National and Cyber Encryption agency which placed restrictions on LGBT dating apps
- Other methods include arresting journalists or dissenters, or cutting off the internet/celluar service entirely
- Oftentimes there will be misinfo campaigns against reports/activists or spyware directed against them.
- Usually social engineering attacks on reporters consists of 3 steps: Reach out via email/DM on a social media platform, infect their phone/OS, extract info/monitor
- Companies/political campaigns will often use "grey market" services to buy followers, positive reviews, etc... (e.g Turkey's AKP)
- Typosquatting is also a popular tactic for various scams and disinfo campaigns to make information look like it came from legitimate websites
- Watch out for fake LinkedIn profiles, fake resumes, and fake personas from everything from celebrities to IT workers.  The fake celebs will often usually promote cryto schemes


### Ch 5: Hackers in the trenches

- <.< (ORLY?!)

"""
A hacker used to be somebody who proactively hacked something to make sure it was resilient to points of failure, including digital intrusions or cyberattacks. Today, say the word hacker, and the person using the word most likely is referring to a person or persons exploiting unauthorized access to a mobile device, social-media account, e-mail, or company’s network or cloud storage. An unethical or black-hat hacker can act alone, as part of a cybercriminal syndicate, or as part of a nation-state-sponsored trained group of elite operatives. Although each black-hat or unethical hacker is unique, here are a few profiles I have built over my years managing forensics cases.
"""

- Groups can range from nation states, to cybercrime gangs, to hactivists
- Those groups that are more well resourced will use potentially hundreds of thousands of bots and sock puppet accounts (often using stolen identities to establish the accounts)
- A common technique is spear phishing to specifically target someone to get them to click on a link/file and infect the target's account/system, other methods include ransomware, malware, keyloggers, etc...
- Other techniques can include password cracking, social engineering, rouge hotspots, etc...

### Ch 6: Anatomy of a manipulation campaign

- During an interview with someone who conducted influece ops, they used a number of different forms of Opsect:
  - Separating domains not on shared servers
  - Rabbit holes and fallback accounts
  - Automation scripts for uploading stories and making sure it looked like they were from independent sources
  - Each separate social media account gets its own VM and VPN
"""
When he used a VPN, he would make sure the counterfeit people would always log in via the same geography—using the same topics, the same virtual machine—and he left nothing to chance. Each fake persona had its own log-in behaviors.
"""
"""
When I ask how large his staff was, he demurs and gives vague responses indicating that the operation at one point was just a few people supporting him but grew over time as his news-manipulation operation became profitable. While his news-copywriting minions worked on his grand plan, he would scour the Internet, conducting a covert-surveillance operation, guzzling down the news from traditional and nontraditional outlets. He created big-data algorithms to chunk through reams of data, showing him the best day and time to reach, say, the soccer moms or the angry white males. “I had every demographic that we wanted to keep, persuade, and motivate, down to when to post on a 24–7 cycle within fifteen-minute increments.”
"""
"""
“The best time for the crazy lies—or the ‘4Chan hour’—is 11 p.m. to 2 a.m. The most potent time slot of the day was 11 a.m. for anything that was a call to action. At 7 a.m. people are just waking up; they want positive stuff—think puppies on morning-news shows. Eleven a.m., that’s totally peak time. Two p.m. to 7 p.m. can be slow, so that’s when you do some tests by placing random stories. It’s essential to hide your tracks and do test cases.
 
"""


### Ch 7: US Elections 2016 to 2018

- Campaign hacks were a thing via spear phishing and spoofed emails
- Once the campaigns were hacked emails/communications were downloaded and forgeries planted among them for maximum impact/embarassment
- State election websites were also attacked with spoofed voter registrations and SQL injects
- Different influence campaigns were focused on different things from voter suppression to wedge issues

"""
One poorly designed feature in a computer system in California opened the entire state’s voter rolls to manipulation. When in 2018 a new “motor voter” program went online that would enable California voters register while visiting the department of motor vehicles, bugs and glitches began coming to light almost immediately. First, it was discovered that the central DMV network was trying to communicate with Internet servers in Croatia. California does not need to be connected to Croatia, so a hack of some sort was suspected. Not much else is known about the Croatia connection, but officials say no data was compromised. Numerous other problems with the rollout shook Californians’ faith in the technology and voter-system integrity: Voters found that the system had assigned them the wrong party preferences, non-California citizens were suddenly registered to vote, and some people who were registered did not recall having ever registered.34 All in all, it is estimated that perhaps more than one hundred thousand errors were made in voter registrations before California’s June 2018 primary.
"""

- The above likely lead to the ouster of CA's CIO Amy Tong

![image](https://github.com/user-attachments/assets/02e0a401-a0c2-4d50-92a3-49a2ba566264)


- To try and fix the issue Payton recommends a top down approach in which the government or org evaluates each state and provides a grade and remediation, along with fusion centers to coordinate intellgince and messages regarding misinfo campaigns
- For individuals to be secure they should check their votor registration, be wary of text messaging/DM scams, and be aware of manipulation campaigns and report fake personas

### Ch 8: America isn't the only target

- Influence campaigns also target France, the UK, Germany, Taiwan, international reporting orgs, etc...
- The influence campaigns usually fall into the category of hack and dump w/ forgeries, pumping disinfo stories, or false social media posts/bots
- Different places have had different responses from committees to laws, to boards of inquiry, or rapid alert systems to combat disinfo campaigns

### Ch 9: The Next Target: What attacks can we expect in 2020 and beyond?

- Expected attacks include voter roll manipulation via accessing the DBs and dumping them or putting them on the dark web or a smash/grab/dox campaign
- Other attack vectors include weak passwords and voter system DDoS
- AI, Deepfakes, and forged leaks will be another attack vector further poisioning the well between truth and fiction


### Ch 10: Death of Democracy

"""
“A small number of very active bots can actually significantly shift public opinion,” says Tauhid Zaman, associate professor of operations management at MIT Sloan School of Management. “And despite social-media companies’ efforts, there are still large numbers of bots out there, constantly tweeting and retweeting, trying to influence real people who vote.”7 This means that, increasingly, fringe views will be overrepresented electorally. This means, also, that voters, repeatedly disenfranchised, will become apathetic. Unless you have a money machine behind you to combat the manipulation or curry favor with the state-sponsored manipulators, you can’t win. The adage used to be that the campaign with the best message that incents voter turnout wins. This is no longer true. The adage is now, Keep your head down, and don’t incite the trolls.
"""

- Cybercriminals/nation states are regularly innovating from Estonia in 2007 to today, there are new methodologies, TTPs, and deepfakes that push various narratives
- Tech companies are falling short despite their prevalince in our lives, even businesses can be faked as up to 11 million businesses on Google Maps are fake according to WSJ
- Social media companies are reluctant to comply with investigations and don't take pages/posts that have red flags very seriously
- Manipulation campaigns are often directed not just at elections, parties, or states, but also at individuals and businesses where bot farms and bombarded reviews can sink a reputation
- Everything/everyone from big tech, to news orgs, to politicians are struggling to keep up with manipulation campaigns to where incremental changes are not good enough

"""
This is the fundamental reason why every day, cybersecurity fails to protect you from manipulation campaigns: Everyone is counting on the user to do the heavy lifting to ensure they are not manipulated.
"""

- Design for safety first, with safeguards ane education in place, and imposting cost on bad actors

"""
We need to establish a global center to focus on tracking the proliferation of cyber manipulation and cybercrime tactics so we can educate users and stop them from becoming victims. The global center would have a “red phone” concept. Just as the red phone provided a direct line of communication during the Cold War between the United States and Russia, global democracies need a red phone that rings into a central organization that can be used in times of democratic disaster. This group must bring together countries, security professionals, media, political parties and politicians, and technology experts to proactively anticipate what countries such as Russia, China, Iran, and North Korea might try next.
"""

- To help put a stop to manipulation tactics/technology everyone must be informed and engaged against bad actors

### Ch 11: WHat Can You Do?

- To stop manipulators require a whole effort of action from social networks/news aggregators to vet posts accurately and quickly, to disincentivizing rage bait posts, to not using information for targeting.
- In reality, the actions people can take are to report election abuses, watch out for clickbait/"alternative" news, watch out for fake/hijacked personas, and check for deepfakes (make sure to verify things at the source, and check the details)
- Keep up to date on current events and developments in cyber manipulation, and check a story using multiple sources
